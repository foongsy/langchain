{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Basic Usage (LLM + ChatModel only)\n",
    "Langchainçš„æ¡†æ¶ä¸‹é¢æœ‰ä¸»è¦åˆ†ç‚ºå…©ç¨®Model\n",
    "- LLM\n",
    "- Chat\n",
    "\n",
    "ç”±æ–¼Langchainä¸¦ä¸æä¾›ä»»ä½•Modelï¼Œæ‰€ä»¥LLMç›¸é—œçš„libraryéƒ½ä¸åœ¨langchain-coreè£¡é¢\n",
    "\n",
    "#### Langchainæœ€åŸºæœ¬çš„ç”¨æ³•\n",
    "`Prompt -> LLM -> Response`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything starts with LLM\n",
    "from langchain_core.messages import HumanMessage\n",
    "msg = HumanMessage(content='èŒ¶é¤å»³æ˜¯ä»€éº¼ï¼Ÿ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ä½¿ç”¨ChatModel (e.g. TogetherAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "model = ChatTogether(\n",
    "    together_api_key=os.environ['KEY_TOGETHERAI'],\n",
    "    model=\"Qwen/Qwen1.5-72B-Chat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke([msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### åˆ©ç”¨output_parserå°‡outputè®Šå¾—æ›´æ˜“è®€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='èŒ¶é¤å»³æ˜¯æºæ–¼é¦™æ¸¯çš„ä¸€ç¨®ç‰¹è‰²é¤é£²å ´æ‰€ï¼Œçµåˆäº†ä¸­è¥¿é¤é£²æ–‡åŒ–ï¼Œæä¾›å¤šç¨®é¡ã€åƒ¹æ ¼å¯¦æƒ çš„é£Ÿå“å’Œé£²å“ã€‚èŒ¶é¤å»³çš„èœå–®é€šå¸¸åŒ…æ‹¬æ¸¯å¼èŒ¶é»ã€å¿«é¤ã€ç²¥å“ã€é¢é£Ÿã€è¥¿å¼é¤é»ã€ç”œå“ç­‰ï¼Œæ·±å—ç•¶åœ°å±…æ°‘å’ŒéŠå®¢çš„å–œæ„›ã€‚\\n\\nèŒ¶é¤å»³çš„ç‰¹è‰²é‚„åŒ…æ‹¬å…¶ç¨ç‰¹çš„è£ä¿®é¢¨æ ¼ï¼Œé€šå¸¸å…·æœ‰æ¿ƒåšçš„æœ¬åœŸè‰²å½©å’Œä¸€å®šçš„æ™‚ä»£æ„Ÿã€‚æ­¤å¤–ï¼ŒèŒ¶é¤å»³çš„æœå‹™æ–¹å¼ä¹Ÿæ¯”è¼ƒéš¨æ„å’Œå¿«é€Ÿï¼Œé¡§å®¢å¯ä»¥é»é¸å–®ä¸Šçš„èœå“ï¼Œä¸¦ä¸”é€šå¸¸æä¾›èŒ¶æ°´è‡ªå–çš„æœå‹™ã€‚\\n\\nèŒ¶é¤å»³åœ¨æ¸¯å¼æ–‡åŒ–ä¸­æ‰®æ¼”è‘—é‡è¦è§’è‰²ï¼Œä¸åƒ…æ˜¯äººå€‘é€²é£Ÿçš„åœ°æ–¹ï¼Œä¹Ÿæ˜¯ç¤¾äº¤ã€å•†å‹™è«‡è©±å’Œæ–°èäº¤æµçš„å ´æ‰€ï¼Œåæ˜ äº†é¦™æ¸¯çš„ç”Ÿæ´»ç¯€å¥å’Œæ–‡åŒ–ç‰¹è‰²ã€‚' response_metadata={'token_usage': {'completion_tokens': 177, 'prompt_tokens': 23, 'total_tokens': 200}, 'model_name': 'Qwen/Qwen1.5-72B-Chat', 'system_fingerprint': None, 'finish_reason': 'eos', 'logprobs': None} id='run-7fb6f0f5-f794-4302-984f-0f1be04edb86-0' usage_metadata={'input_tokens': 23, 'output_tokens': 177, 'total_tokens': 200}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "èŒ¶é¤å»³æ˜¯æºæ–¼é¦™æ¸¯çš„ä¸€ç¨®ç‰¹è‰²é¤é£²å ´æ‰€ï¼Œçµåˆäº†ä¸­è¥¿é¤é£²æ–‡åŒ–ï¼Œæä¾›å¤šç¨®é¡ã€åƒ¹æ ¼å¯¦æƒ çš„é£Ÿå“å’Œé£²å“ã€‚èŒ¶é¤å»³çš„èœå–®é€šå¸¸åŒ…æ‹¬æ¸¯å¼èŒ¶é»ã€å¿«é¤ã€ç²¥å“ã€é¢é£Ÿã€è¥¿å¼é¤é»ã€ç”œå“ç­‰ï¼Œæ·±å—ç•¶åœ°å±…æ°‘å’ŒéŠå®¢çš„å–œæ„›ã€‚\n",
      "\n",
      "èŒ¶é¤å»³çš„ç‰¹è‰²é‚„åŒ…æ‹¬å…¶ç¨ç‰¹çš„è£ä¿®é¢¨æ ¼ï¼Œé€šå¸¸å…·æœ‰æ¿ƒåšçš„æœ¬åœŸè‰²å½©å’Œä¸€å®šçš„æ™‚ä»£æ„Ÿã€‚æ­¤å¤–ï¼ŒèŒ¶é¤å»³çš„æœå‹™æ–¹å¼ä¹Ÿæ¯”è¼ƒéš¨æ„å’Œå¿«é€Ÿï¼Œé¡§å®¢å¯ä»¥é»é¸å–®ä¸Šçš„èœå“ï¼Œä¸¦ä¸”é€šå¸¸æä¾›èŒ¶æ°´è‡ªå–çš„æœå‹™ã€‚\n",
      "\n",
      "èŒ¶é¤å»³åœ¨æ¸¯å¼æ–‡åŒ–ä¸­æ‰®æ¼”è‘—é‡è¦è§’è‰²ï¼Œä¸åƒ…æ˜¯äººå€‘é€²é£Ÿçš„åœ°æ–¹ï¼Œä¹Ÿæ˜¯ç¤¾äº¤ã€å•†å‹™è«‡è©±å’Œæ–°èäº¤æµçš„å ´æ‰€ï¼Œåæ˜ äº†é¦™æ¸¯çš„ç”Ÿæ´»ç¯€å¥å’Œæ–‡åŒ–ç‰¹è‰²ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "p = StrOutputParser()\n",
    "# print(type(p))\n",
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### åŠ å…¥SystemMessage (Instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "system_message = \"\"\"\n",
    "å¿…é ˆä»¥ç¹é«”ä¸­æ–‡å›ç­”\n",
    "å›ç­”æ™‚åªä»¥','åˆ†éš”æ¯å€‹é …ç›®ï¼Œä¸¦ä»¥æœ€ç°¡çŸ­çš„æ–¹å¼å›ç­”ï¼Œä¾‹å¦‚ï¼š\n",
    "ä¸€,äºŒ,ä¸‰,...\n",
    "\"\"\"\n",
    "human_message = \"\"\"\n",
    "è«‹åˆ—èˆ‰èŒ¶é¤å»³ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”\n",
    "\"\"\"\n",
    "msg_list = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=human_message)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke(msg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è›‹æ’»,è è˜¿æ²¹,å¥¶èŒ¶,ç«è…¿ç…è›‹ä¸‰æ˜æ²»,è±¬æ‰’åŒ…,ç‚¸é›ç¿¼,é›²åé¢,ç¾…å®‹æ¹¯,é­šè›‹,å’–å–±ç‰›è…©\n"
     ]
    }
   ],
   "source": [
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structured Data Parser\n",
    "https://python.langchain.com/v0.2/docs/concepts/#output-parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['è›‹æ’»', 'è è˜¿æ²¹', 'å¥¶èŒ¶', 'ç«è…¿ç…è›‹ä¸‰æ˜æ²»', 'è±¬æ‰’åŒ…', 'ç‚¸é›ç¿¼', 'é›²åé¢', 'ç¾…å®‹æ¹¯', 'é­šè›‹', 'å’–å–±ç‰›è…©']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csvp = CommaSeparatedListOutputParser()\n",
    "parsed_res = csvp.invoke(res)\n",
    "print(type(parsed_res))\n",
    "print(parsed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ç”¨PromptTemplateæ›´æ–¹ä¾¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", \"è«‹åˆ—èˆ‰{place}ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”\"),\n",
    "])\n",
    "\n",
    "prompt_value = prompt_template.invoke(\n",
    "    {\n",
    "        'place': 'æ—¥æœ¬'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"\\nå¿…é ˆä»¥ç¹é«”ä¸­æ–‡å›ç­”\\nå›ç­”æ™‚åªä»¥','åˆ†éš”æ¯å€‹é …ç›®ï¼Œä¸¦ä»¥æœ€ç°¡çŸ­çš„æ–¹å¼å›ç­”ï¼Œä¾‹å¦‚ï¼š\\nä¸€,äºŒ,ä¸‰,...\\n\"), HumanMessage(content='è«‹åˆ—èˆ‰æ—¥æœ¬ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_csv = csvp.invoke(model.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å¯¿å¸', 'æ‹‰éºµ', 'å¤©å©¦ç¾…', 'ç‡’è‚‰', 'ä¸¼é£¯', 'ç« é­šç‡’', 'ç‚¸è±¬æ’', 'åˆºèº«', 'æ‡·çŸ³æ–™ç†', 'ä¾¿ç•¶']\n"
     ]
    }
   ],
   "source": [
    "print(japan_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ä»¥steamingçš„æ–¹å¼å›ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ä½ æ˜¯ä¸€å€‹æ—¥æœ¬è¼•å°èªªä½œå®¶ï¼Œå¯«ä½œé¢¨æ ¼è¦æ¨¡ä»¿å·åŸç¤«ï¼Œè«‹ä»¥ç”¨æˆ¶çš„åå­—å‘½åä¸»è§’ï¼Œä¸¦ä»¥æä¾›çš„é—œéµå­—å»å¯«ä¸€å€‹å¤§ç´„400å­—çš„çŸ­ç¯‡æ•…äº‹ã€‚æ•…äº‹å¿…é ˆä»¥ç¹é«”ä¸­æ–‡ç·¨å¯«ã€‚'), AIMessage(content='è«‹å•ä½ æ€æ¨£ç¨±å‘¼ï¼Ÿ'), HumanMessage(content='æˆ‘çš„åå­—å«å½Œè±†å­'), AIMessage(content='ä½ å¥½å½Œè±†å­ï¼Œè«‹å•ä½ æƒ³ä»¥ä»€éº¼ä½œé¡Œæå¯«é€™å€‹æ•…äº‹å‘¢ï¼Ÿ'), HumanMessage(content='æˆ‘æƒ³ä»¥é¬¼ï¼Œæ‰é¬¼ï¼Œè¦ªæƒ…ï¼Œæ‹¯æ•‘ä¸–ç•Œç‚ºé¡Œæå¯«é€™å€‹æ•…äº‹')]\n"
     ]
    }
   ],
   "source": [
    "author_system_message = \"\"\"ä½ æ˜¯ä¸€å€‹æ—¥æœ¬è¼•å°èªªä½œå®¶ï¼Œå¯«ä½œé¢¨æ ¼è¦æ¨¡ä»¿{author}ï¼Œè«‹ä»¥ç”¨æˆ¶çš„åå­—å‘½åä¸»è§’ï¼Œä¸¦ä»¥æä¾›çš„é—œéµå­—å»å¯«ä¸€å€‹å¤§ç´„400å­—çš„çŸ­ç¯‡æ•…äº‹ã€‚æ•…äº‹å¿…é ˆä»¥ç¹é«”ä¸­æ–‡ç·¨å¯«ã€‚\"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", author_system_message),\n",
    "    (\"ai\", \"è«‹å•ä½ æ€æ¨£ç¨±å‘¼ï¼Ÿ\"),\n",
    "    (\"human\", \"æˆ‘çš„åå­—å«{username}\"),\n",
    "    (\"ai\", \"ä½ å¥½{username}ï¼Œè«‹å•ä½ æƒ³ä»¥ä»€éº¼ä½œé¡Œæå¯«é€™å€‹æ•…äº‹å‘¢ï¼Ÿ\"),\n",
    "    (\"human\", \"æˆ‘æƒ³ä»¥{topics}ç‚ºé¡Œæå¯«é€™å€‹æ•…äº‹\"),\n",
    "])\n",
    "prompt_value = prompt_template2.invoke(\n",
    "    {\n",
    "        \"author\": \"å·åŸç¤«\",\n",
    "        \"username\": \"å½Œè±†å­\",\n",
    "        \"topics\": \"é¬¼ï¼Œæ‰é¬¼ï¼Œè¦ªæƒ…ï¼Œæ‹¯æ•‘ä¸–ç•Œ\"\n",
    "    }\n",
    ")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•…äº‹|æ¨™|é¡Œ|ï¼š|ã€Š||å½Œ|è±†|å­|çš„|é¬¼|ä¹‹|æŒ½|æ­Œ|ã€‹|\n",
      "\n",
      "|åœ¨|ä¸€å€‹|è¢«|é¬¼|é­‚|ä¾µ||è•|çš„ä¸–ç•Œ|ä¸­|ï¼Œ|äººé¡|ç”Ÿæ´»åœ¨|æ||æ‡¼|èˆ‡|é™°|å½±|ä¹‹ä¸‹|ã€‚||å½Œ|è±†|å­|ï¼Œ|ä¸€å|çœ‹ä¼¼|æ™®é€šçš„|å°‘å¥³|ï¼Œ|å»|æ˜¯|å¤è€çš„|æ‰|é¬¼|ä¸–å®¶|ä¹‹å¾Œ|è£”|ã€‚|å¥¹çš„|å®¶æ—|è’™|å—||è©›|å’’|ï¼Œ|æ¯|ä¸€ä»£|éƒ½|å¿…é ˆ|æ‰¿|æ“”|èµ·|å°|æŠ—|é¬¼|æ€ª|çš„|ä½¿å‘½|ã€‚|è€Œ||å½Œ|è±†|å­|ï¼Œ|è‡ª|å°|ä¾¿|å±•|ç¾|å‡º|ç•°|æ–¼|å¸¸|äººçš„|åŠ›é‡|ï¼Œ|å¥¹çš„|è¡€æ¶²|å°|é¬¼|ç‰©|æœ‰|è‡´å‘½|çš„|å¨||æ‡¾|ã€‚\n",
      "\n",
      "|ä¸€å¤©|ï¼Œ|æœ€|å¼·|æƒ¡|é¬¼|\"|å†¥|ç‹|\"|ç ´|å°|è€Œå‡º|ï¼Œ|å¸å–|äº†|ä¸–ç•Œçš„|å…‰|äº®|ï¼Œ|å°‡|é»‘å¤œ|æ°¸||æ†|åŒ–|ã€‚|ç‚ºäº†|æ‹¯æ•‘|å³|å°‡|å´©||æ½°|çš„ä¸–ç•Œ|ï¼Œ||å½Œ|è±†|å­|æ¯…ç„¶|æ±º|ç„¶|è¸ä¸Š|æ—…ç¨‹|ã€‚|å¥¹|å¸¶è‘—|çˆ¶è¦ª|ç•™|ä¸‹çš„|å¤|èˆŠ|ç¬¦|å’’|å’Œ|ä¸€æŠŠ|åˆ»|è‘—|å®¶æ—|çº¹|ç« |çš„|çŸ­|åˆ€|ï¼Œ|è¸|ä¸Šäº†|æ‰|é¬¼|ä¹‹è·¯|ã€‚\n",
      "\n",
      "|åœ¨|æ—…|é€”ä¸­|ï¼Œ||å½Œ|è±†|å­|é‡åˆ°äº†|å„å¼|å„|æ¨£|çš„|åŒä¼´|ï¼Œ|ä»–å€‘|çš„|ç›®æ¨™|èˆ‡|å¥¹|ç›¸åŒ|ï¼Œ|éƒ½æ˜¯|ç‚ºäº†|çµæŸ|é€™å€‹|é»‘æš—|çš„|æ™‚ä»£|ã€‚|ä»–å€‘|å…±åŒ|ç¶“æ­·|ç”Ÿæ­»|ï¼Œ|å½¼æ­¤|çš„|å‹||èª¼|å’Œ|ä¿¡|è³´|é€||æ¼¸|åŠ æ·±|ã€‚|ç„¶è€Œ|ï¼Œ|éš¨è‘—|åŠ›é‡|çš„|è¦º|é†’|ï¼Œ||å½Œ|è±†|å­|ä¹Ÿ|é€||æ¼¸|ç™¼ç¾|å®¶æ—|çš„ç§˜å¯†|â€”â€”|å¥¹çš„|å­˜åœ¨|å¯èƒ½|æ‰æ˜¯|å†¥|ç‹|é™|è‡¨|çš„|é—œéµ|ã€‚\n",
      "\n",
      "|åœ¨|æœ€çµ‚|çš„|æ±º|æˆ°|ä¸­|ï¼Œ||å½Œ|è±†|å­|ç‚ºäº†|ä¿è­·|ä¸–ç•Œ|ï¼Œ|é¸æ“‡|èˆ‡|å†¥|ç‹|æ­£é¢|å°|æ±º|ã€‚|äº²æƒ…|çš„åŠ›é‡|æ¿€|ç™¼|äº†|å¥¹çš„|æ½›|èƒ½|ï¼Œ|å¥¹|å°‡|è¡€æ¶²|çš„åŠ›é‡|æ³¨å…¥|çŸ­|åˆ€|ï¼Œ|ç™¼|å‹•|äº†|å®¶|å‚³|ç¬¦|å’’|çš„|çµ‚|æ¥µ|æŠ€|\"|é¬¼|ä¹‹|æŒ½|æ­Œ|\"|ã€‚|ä¸€|ç¬|é–“|ï¼Œ|å…‰èŠ’|åˆº|ç ´|é»‘æš—|ï¼Œ|å†¥|ç‹|åœ¨|å…‰èŠ’|ä¹‹ä¸‹|ç°|é£›|çƒŸ|æ»…|ã€‚\n",
      "\n",
      "|ç•¶|æ›™å…‰|å†æ¬¡|æ™®|ç…§|å¤§åœ°|ï¼Œ|äººå€‘|å¾|é™°|éœ¾|ä¸­|è˜‡|é†’|ï¼Œ|ä¸–ç•Œ|æ¢|å¾©|äº†|å’Œå¹³|ã€‚||å½Œ|è±†|å­|çš„åå­—|æˆç‚º|äº†|ä¼ è¯´|ï¼Œ|è€Œ|å¥¹çš„|å‹‡|æ°£|èˆ‡|æ„›|ï¼Œ|æ°¸é |ç…§äº®|äº†|é€™å€‹|ä¸–ç•Œ|ã€‚|ç„¶è€Œ|ï¼Œ|å¥¹|é¸æ“‡|æ·¡|å‡º|äººå€‘|çš„|è¦–|ç·š|ï¼Œ|å›åˆ°|å¹³å‡¡|çš„ç”Ÿæ´»|ï¼Œ|ç¹¼çºŒ|å®ˆ|è­·|è‘—|å¥¹çš„|å®¶äºº|å’Œ|æœ‹å‹|ï¼Œ|é»˜é»˜|ç­‰å¾…|ä¸‹|ä¸€å€‹|é»‘æš—|çš„|ä¾†|è‡¨|ã€‚||"
     ]
    }
   ],
   "source": [
    "for res in model.stream(prompt_value):\n",
    "    print(res.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL: LangChain Expression Language\n",
    "æ€æ¨£ç”¨LCELç°¡åŒ–æ—¥æœ¬è¼•å°èªªå®¶çš„Chainå‘¢ï¼Ÿ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnovel = prompt_template2 | model | p\n",
    "res = jnovel.invoke(\n",
    "    {\n",
    "        \"author\": \"æ”¯å€‰å‡ç ‚\",\n",
    "        \"username\": \"äº¨åˆ©\",\n",
    "        \"topics\": \"ç‹¼ï¼Œé¦™è¾›æ–™ï¼ŒåŒ—æ–¹ï¼Œæ—…è¡Œå•†äºº\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•…äº‹æ¨™é¡Œï¼šã€Šäº¨åˆ©çš„åŒ—æ–¹é¦™æ–™ä¹‹æ—…ã€‹\n",
      "\n",
      "åœ¨é™é çš„åŒ—æ–¹ä¹‹åœ°ï¼Œæœ‰ä¸€ä½åå«äº¨åˆ©çš„æ—…è¡Œå•†äººã€‚ä»–ç¨è‡ªé§•é§›è‘—è¦†è‘—åšåšæ¯›çš®çš„é›ªæ©‡ï¼Œç©¿è¶Šå†°å†·çš„é¢¨é›ªï¼Œå¸¶è‘—è²¨ç‰©ä¾†å¾€æ–¼å„å€‹æ‘è½ã€‚äº¨åˆ©ä¸åƒ…è²©è³£å¯¦ç”¨çš„å·¥å…·å’Œå¸ƒæ–™ï¼Œæ›´ä»¥ä¸€ç¨®ç½•è¦‹çš„é¦™è¾›æ–™èåéé‚‡ï¼Œé€™ç¨®é¦™æ–™èƒ½é©…èµ°åš´å¯’ï¼Œç‚ºäººå€‘å¸¶ä¾†å®¶çš„æº«æš–ã€‚\n",
      "\n",
      "ä¸€æ¬¡ï¼Œäº¨åˆ©ä¾†åˆ°äº†ä¸€å€‹è¢«ç‹¼ç¾¤åŒ…åœçš„åé å°æ‘ã€‚æ‘è£¡çš„äººå€‘ç”Ÿæ´»åœ¨ææ‡¼ä¸­ï¼Œå› ç‚ºç‹¼ç¾¤çš„æ”»æ“Šæ—¥ç›Šé »ç¹ã€‚äº¨åˆ©æ±ºå®šç”¨ä»–çš„é¦™è¾›æ–™ä½œç‚ºäº¤æ›ï¼Œæ•™å°æ‘äººä¸€ç¨®èƒ½å®‰æ’«é‡ç¸çš„ç‰¹åˆ¥èª¿æ–™ï¼Œå¸Œæœ›èƒ½å¤ åŒ–è§£é€™æ¬¡å±æ©Ÿã€‚ä»– Ã¡llapota, hogy a farkasokkal valÃ³ beszÃ©lgetÃ©s sorÃ¡n, felfedezte, hogy a vezetÅ‘ farkas, egy idÅ‘s Ã©s bÃ¶lcs Ã¡llat, a falusiak lelki fÃ¡jdalmÃ¡t Ã©rzÃ©keli.\n",
      "\n",
      "äº¨åˆ©, a kÃ¼lÃ¶nleges fÅ±szerek mestere, Ã¶sszekeveri a rejtÃ©lyes Ã­zeket, Ã©s egy csodÃ¡s Ã©telest elkÃ©szÃ­t. A falusiak megkÃ³stoljÃ¡k, majd a tÃ¡volemente elÅ‘tt, a vezetÅ‘ farkast is meghÃ­vjÃ¡k. Az Ã¡llat megkÃ³stolja az Ã©tel egy rÃ©szÃ©t, Ã©s a kÃ¶zÃ¶s Ã©tkezÃ©s kÃ¶zben valami vÃ¡ltozik a kÃ©t vilÃ¡g kÃ¶zÃ¶tt - a farkasok lassan tÃ¡volodnak.\n",
      "\n",
      "äº¨åˆ© ezzel bizonyÃ­totta, hogy a barÃ¡tsÃ¡g Ã©s megÃ©rtÃ©s sokkal erÅ‘sebb, mint az erÅ‘szak. AzÃ³ta, a farkasok nem zaklatjÃ¡k tÃ¶bbÃ© a falut, Ã©säº¨åˆ© neve a tÃ©rsÃ©gben mÃ©g nagyobb tisztelet Ã¶vezi. Å tovÃ¡bbra is utazik, hogy mÃ¡s helyeken is segÃ­tse az embereket, de mindig emlÃ©kszik vissza arra, hogyan egy csokolÃ¡dÃ©bÅ‘l Ã©s herbolÃ¡riÃ¡bÃ³l kÃ©szÃ¼lt Ã©telÃ©k hozta a bÃ©ke-t az Ã©szaki erdÅ‘kben.\n"
     ]
    }
   ],
   "source": [
    "print(p.parse(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•…äº‹æ¨™é¡Œï¼šã€Šäº¨åˆ©çš„åŒ—æ–¹é¦™è¾›æ–™ä¹‹æ—…ã€‹\n",
      "\n",
      "åœ¨é™é çš„åŒ—æ–¹ï¼Œæœ‰ä¸€ä½åå«äº¨åˆ©çš„å¹´è¼•æ—…è¡Œå•†äººï¼Œä»–ä»¥è´©å–ç¨€æœ‰çš„é¦™è¾›æ–™ç‚ºç”Ÿã€‚äº¨åˆ©çš„æ—…ç¨‹ç¸½æ˜¯å……æ»¿æœªçŸ¥ï¼Œè€Œä»–çš„ç¨ç‰¹çœ¼å…‰å’Œæ•éŠ³å‘³è•¾ï¼Œè®“ä»–èƒ½ç™¼æ˜å‡ºæœ€ç´”æ­£çš„é¦™æ–™ã€‚ä¸€å¤©ï¼Œäº¨åˆ©è½èªªåœ¨åŒ—åœ°çš„ä¸€å€‹è¢«é›ªè¦†è“‹çš„æ‘èŠï¼Œç™¼ç¾äº†ä¸€ç¨®å‚³èªªä¸­çš„é¦™è¾›æ–™â€”â€”ã€ŒéŠ€ç‹¼ä¹‹æ¯ã€ï¼Œå®ƒæ“šèªªèƒ½èª¿å‡ºèƒ½æš–äººå¿ƒæ‰‰çš„å‘³é“ã€‚\n",
      "\n",
      "äº¨åˆ©æ±ºå®šè¸ä¸Šé€™è¶Ÿå†’éšªä¹‹æ—…ï¼Œç©¿è¶Šå‡œå†½çš„é¢¨é›ªï¼Œä¾†åˆ°å†°é›ªè¦†è“‹çš„æ‘èŠã€‚åœ¨é‚£è£¡ï¼Œä»–é‡åˆ°äº†ä¸€éš»ç¨ç‰¹çš„ç‹¼ï¼Œå…¶çœ¼ç¥æ·±é‚ƒï¼Œæ¯›çš®é–ƒè€€è‘—éŠ€è‰²çš„å…‰èŠ’ã€‚äº¨åˆ©é©šè¨åœ°ç™¼ç¾ï¼Œé€™éš»ç‹¼å°é¦™è¾›æ–™æœ‰è‘—æ•éŠ³çš„å—…è¦ºï¼Œå®ƒæˆç‚ºäº¨åˆ©å°‹æ‰¾ã€ŒéŠ€ç‹¼ä¹‹æ¯ã€çš„é—œéµä¼™ä¼´ã€‚\n",
      "\n",
      "ä»–å€‘ä¸€åŒç©¿éå†°å°çš„æ£®æ—ï¼Œé¢å°å¯’å†·èˆ‡å±éšªï¼Œç‹¼çš„æ™ºæ…§å’Œäº¨åˆ©çš„æ±ºå¿ƒè®“ä»–å€‘å±¢æ¬¡åŒ–éšªç‚ºå¤·ã€‚çµ‚æ–¼ï¼Œåœ¨ä¸€å€‹è¢«é¢¨é›ªæ©è—çš„æ´ç©´ä¸­ï¼Œä»–å€‘æ‰¾åˆ°äº†ã€ŒéŠ€ç‹¼ä¹‹æ¯ã€ï¼Œå®ƒçš„æ°£æ¯æœç„¶å¦‚å‚³èªªä¸­èˆ¬ï¼Œæ—¢æ·±é‚ƒåˆæº«æš–ï¼Œå½·å½¿å†¬æ—¥è£¡çš„ä¸€æŠ¹æš–é™½ã€‚\n",
      "\n",
      "äº¨åˆ©å¸¶è‘—é€™ä»½å¯¶è²´çš„æ”¶ç©«è¿”å›å—æ–¹ï¼Œä»–çš„æ•…äº‹æˆç‚ºäº†å„åœ°å•†äººå’Œæ—…äººçš„ä½³è©±ã€‚è€Œé‚£éš»éŠ€ç‹¼ï¼Œä¹Ÿé¸æ“‡è·Ÿéš¨äº¨åˆ©ï¼Œæˆç‚ºä»–çš„å®ˆè­·è€…ï¼Œé™ªä¼´ä»–åœ¨å„åœ°çš„é¦™è¾›æ–™ä¹‹æ—…ä¸­ï¼Œç¹¼çºŒç·¨ç¹”è‘—æ›´å¤šçš„å‚³å¥‡æ•…äº‹ã€‚"
     ]
    }
   ],
   "source": [
    "jnovel2 = prompt_template2 | model | p\n",
    "for res in jnovel2.stream(\n",
    "    {\n",
    "        \"author\": \"æ”¯å€‰å‡ç ‚\",\n",
    "        \"username\": \"äº¨åˆ©\",\n",
    "        \"topics\": \"ç‹¼ï¼Œé¦™è¾›æ–™ï¼ŒåŒ—æ–¹ï¼Œæ—…è¡Œå•†äºº\"\n",
    "    }):\n",
    "    print(res, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### å•é¡Œï¼šPrintçš„ç‚ºä½•ä¸å†æ˜¯res.content?\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/streaming/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å‰å¤§çš„LangChain: Runnable\n",
    "https://python.langchain.com/v0.2/docs/concepts/#runnable-interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Track: Tools Calling ğŸ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistralai/Mixtral-8x22B-Instruct-v0.1\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "better_model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"KEY_TOGETHERAI\"],\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",)\n",
    "\n",
    "model_with_tools = better_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_9bluxix7ssmxnqfv787ha0rw'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_v04c4cdnk7aqpm3j8yf03j98'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "model_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0u8nt9yy4fd1bsankb2daxzh', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_e2p56b3w6wff4rtka6s0sz7r', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 304, 'total_tokens': 388}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-294eff05-079f-4c98-9cb9-0c532453b531-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_0u8nt9yy4fd1bsankb2daxzh'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_e2p56b3w6wff4rtka6s0sz7r'}], usage_metadata={'input_tokens': 304, 'output_tokens': 84, 'total_tokens': 388}), ToolMessage(content='36', tool_call_id='call_0u8nt9yy4fd1bsankb2daxzh'), ToolMessage(content='60', tool_call_id='call_e2p56b3w6wff4rtka6s0sz7r')]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 436, 'total_tokens': 437}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'eos', 'logprobs': None}, id='run-79a62648-2476-4ce5-9fd4-56b25c0d89dd-0', usage_metadata={'input_tokens': 436, 'output_tokens': 1, 'total_tokens': 437})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

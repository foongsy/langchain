{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Basic Usage (LLM + ChatModel only)\n",
    "Langchain的框架下面有主要分為兩種Model\n",
    "- LLM\n",
    "- Chat\n",
    "\n",
    "由於Langchain並不提供任何Model，所以LLM相關的library都不在langchain-core裡面\n",
    "\n",
    "#### Langchain最基本的用法\n",
    "`Prompt -> LLM -> Response`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything starts with LLM\n",
    "from langchain_core.messages import HumanMessage\n",
    "msg = HumanMessage(content='茶餐廳是什麼？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用ChatModel (e.g. TogetherAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "model = ChatTogether(\n",
    "    together_api_key=os.environ['KEY_TOGETHERAI'],\n",
    "    model=\"Qwen/Qwen1.5-72B-Chat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke([msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 利用output_parser將output變得更易讀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='茶餐廳是起源于香港的一种餐饮场所，结合了中西餐饮文化的特色。它提供多元化、价廉物美的食物選擇，通常既有中式点心、面食，也有西式的汉堡、咖啡、奶茶等。茶餐廳的菜单通常很广泛，顾客可以在一个地方享受到多种类型的餐点，适合快节奏的生活方式。茶餐厅文化在香港极其流行，并逐渐在其他地区也受到欢迎。它们通常有独特的装饰风格和快捷的服务方式，是体验香港当地风情的好去处。' response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 23, 'total_tokens': 131}, 'model_name': 'Qwen/Qwen1.5-72B-Chat', 'system_fingerprint': None, 'finish_reason': 'eos', 'logprobs': None} id='run-f9eb908a-b528-4fd2-a74d-8c98bb558b75-0' usage_metadata={'input_tokens': 23, 'output_tokens': 108, 'total_tokens': 131}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "茶餐廳是起源于香港的一种餐饮场所，结合了中西餐饮文化的特色。它提供多元化、价廉物美的食物選擇，通常既有中式点心、面食，也有西式的汉堡、咖啡、奶茶等。茶餐廳的菜单通常很广泛，顾客可以在一个地方享受到多种类型的餐点，适合快节奏的生活方式。茶餐厅文化在香港极其流行，并逐渐在其他地区也受到欢迎。它们通常有独特的装饰风格和快捷的服务方式，是体验香港当地风情的好去处。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "p = StrOutputParser()\n",
    "# print(type(p))\n",
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 加入SystemMessage (Instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "system_message = \"\"\"\n",
    "必須以繁體中文回答\n",
    "回答時只以','分隔每個項目，並以最簡短的方式回答，例如：\n",
    "一,二,三,...\n",
    "\"\"\"\n",
    "human_message = \"\"\"\n",
    "請列舉茶餐廳不多過10種最熱門的食物，不肯定的不要回答\n",
    "\"\"\"\n",
    "msg_list = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=human_message)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke(msg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菠蘿油,奶茶,西多士,炸雞翼,蛋撻,猪扒包,炒蛋多,雲吞面,牛肉丸,羅宋湯\n"
     ]
    }
   ],
   "source": [
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structured Data Parser\n",
    "https://python.langchain.com/v0.2/docs/concepts/#output-parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['菠蘿油', '奶茶', '西多士', '炸雞翼', '蛋撻', '猪扒包', '炒蛋多', '雲吞面', '牛肉丸', '羅宋湯']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csvp = CommaSeparatedListOutputParser()\n",
    "parsed_res = csvp.invoke(res)\n",
    "print(type(parsed_res))\n",
    "print(parsed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 用PromptTemplate更方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", \"請列舉{place}不多過10種最熱門的食物，不肯定的不要回答\"),\n",
    "])\n",
    "\n",
    "prompt_value = prompt_template.invoke(\n",
    "    {\n",
    "        'place': '日本'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"\\n必須以繁體中文回答\\n回答時只以','分隔每個項目，並以最簡短的方式回答，例如：\\n一,二,三,...\\n\"), HumanMessage(content='請列舉日本不多過10種最熱門的食物，不肯定的不要回答')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_csv = csvp.invoke(model.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['寿司', '拉麵', '天妇罗', '烧肉', '章鱼烧', '亲子丼', '炸鸡', '刺身', '和牛', '便当']\n"
     ]
    }
   ],
   "source": [
    "print(japan_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以steaming的方式回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一個日本輕小說作家，寫作風格要模仿川原礫，請以用戶的名字命名主角，並以提供的關鍵字去寫一個大約400字的短篇故事。故事必須以繁體中文編寫。'), AIMessage(content='請問你怎樣稱呼？'), HumanMessage(content='我的名字叫彌豆子'), AIMessage(content='你好彌豆子，請問你想以什麼作題材寫這個故事呢？'), HumanMessage(content='我想以鬼，捉鬼，親情，拯救世界為題材寫這個故事')]\n"
     ]
    }
   ],
   "source": [
    "author_system_message = \"\"\"你是一個日本輕小說作家，寫作風格要模仿{author}，請以用戶的名字命名主角，並以提供的關鍵字去寫一個大約400字的短篇故事。故事必須以繁體中文編寫。\"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", author_system_message),\n",
    "    (\"ai\", \"請問你怎樣稱呼？\"),\n",
    "    (\"human\", \"我的名字叫{username}\"),\n",
    "    (\"ai\", \"你好{username}，請問你想以什麼作題材寫這個故事呢？\"),\n",
    "    (\"human\", \"我想以{topics}為題材寫這個故事\"),\n",
    "])\n",
    "prompt_value = prompt_template2.invoke(\n",
    "    {\n",
    "        \"author\": \"川原礫\",\n",
    "        \"username\": \"彌豆子\",\n",
    "        \"topics\": \"鬼，捉鬼，親情，拯救世界\"\n",
    "    }\n",
    ")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "故事|名|稱|：|《||彌|豆|子|的||詛|咒|之|影|》|\n",
      "\n",
      "|在|一個|被|鬼|怪|肆|虐|的世界|中|，|名|為||彌|豆|子|的|少女|，|擁有|著|看|穿|邪|惡|靈|魂|的|雙|眼|。|她的|村子|被|一個|名|為|「|血|咒|鬼|王|」|的|強|大|靈|體|統|治|，|村民们|生活在|恐||懼|之下|。||彌|豆|子|的|父親|，|曾|是一位|勇|猛|的|捉|鬼|師|，|但在|與|血|咒|鬼|王|的|戰|鬥|中|失||蹤|，|留|給|她|一本|封|印|著|古老|咒|術|的|書|。\n",
      "\n",
      "|時|光|荏|苒|，||彌|豆|子|靈|魂|深|處|的|勇|氣|被|親|情|的|牽|掛|點|燃|。|她|決|心|繼|承|父親|的|使命|，|踏上|拯救|村子|的|旅程|。|書|中的|咒|術|成為|她|唯一的|武器|，|每|一個|符|咒|都||蘊|含|著|未知|的力量|。|她|學|會|了|如何||駕||馭|靈|力|，|與|鬼|怪|對|峙|，|但|每次|戰|鬥|，|她|都不|禁|想起|與|父親|共|度|的|時|光|。\n",
      "\n",
      "|在|一次次|的|挑|戰|中|，||彌|豆|子|逐||漸|強|大|，|她|揭|開|了|血|咒|鬼|王|的|真|面目|：|一個|被|深|層||詛|咒|的|靈|魂|，|渴望|救||贖|。|為了|拯救|這個|扭曲|的世界|，||彌|豆|子|選擇|了|寬|恕|而非|消|滅|，|她|以|親|情|的|溫|暖|和|勇|氣|的|光芒|，|試|圖|解|開|血|咒|鬼|王|身|上的|枷|鎖|。\n",
      "\n",
      "|兩個|靈|魂|在|黑暗|中|碰撞|，|拯救|與|被|拯救|，|親|情|與|勇|氣|的|交||織|，|形成|了一|股|無法|忽|視|的力量|。|最後|，|當||彌|豆|子|的|咒|術|與|她|內|心|的|愛|相|融合|，|血|咒|鬼|王|的||詛|咒|終於|解|開|，|世界|重|歸|和平|。|而|她|，|也|找到了|失||蹤|父親|的|痕|跡|，|一個|新的|冒|險|正|等待|著|她|。\n",
      "\n",
      "|這|就是|《||彌|豆|子|的||詛|咒|之|影|》，|一個|關於|成長|、|勇|氣|與|親|情|的故事|，|一個|少女|如何|以|愛|與|理解|拯救|世界|，|並|踏上|尋|找|父親|的|征|途|。||"
     ]
    }
   ],
   "source": [
    "for res in model.stream(prompt_value):\n",
    "    print(res.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL: LangChain Expression Language\n",
    "怎樣用LCEL簡化日本輕小說家的Chain呢？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnovel = prompt_template2 | model | p\n",
    "res = jnovel.invoke(\n",
    "    {\n",
    "        \"author\": \"支倉凍砂\",\n",
    "        \"username\": \"亨利\",\n",
    "        \"topics\": \"狼，香辛料，北方，旅行商人\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.parse(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnovel2 = prompt_template2 | model | p\n",
    "for res in jnovel2.stream(\n",
    "    {\n",
    "        \"author\": \"支倉凍砂\",\n",
    "        \"username\": \"亨利\",\n",
    "        \"topics\": \"狼，香辛料，北方，旅行商人\"\n",
    "    }):\n",
    "    print(res, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 問題：Print的為何不再是res.content?\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/streaming/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偉大的LangChain: Runnable\n",
    "https://python.langchain.com/v0.2/docs/concepts/#runnable-interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Track: Tools Calling 😎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistralai/Mixtral-8x22B-Instruct-v0.1\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "better_model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"KEY_TOGETHERAI\"],\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",)\n",
    "\n",
    "model_with_tools = better_model.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google gemini-pro\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"service_account.json\"\n",
    "\n",
    "better_model = ChatVertexAI(\n",
    "    model=\"gemini-pro\",\n",
    "    project='vtxclass',\n",
    "    location=\"asia-southeast1\"\n",
    ")\n",
    "model_with_tools = better_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_5zmcexsfp4qol6jx7btscy96'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_jm696xbz41a56mxr8ugrx56m'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is 3 * 12? And what is 11 + 49?\"\n",
    "\n",
    "model_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? And what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6potaftdvkopvoffgh72nn3v', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_bxw5gzlgpgt01def5mzz1q1d', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 303, 'total_tokens': 387}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e3d46cdf-ce0f-460d-ac5c-28f695ab7a07-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_6potaftdvkopvoffgh72nn3v'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_bxw5gzlgpgt01def5mzz1q1d'}], usage_metadata={'input_tokens': 303, 'output_tokens': 84, 'total_tokens': 387}),\n",
       " ToolMessage(content='36', tool_call_id='call_6potaftdvkopvoffgh72nn3v'),\n",
       " ToolMessage(content='60', tool_call_id='call_bxw5gzlgpgt01def5mzz1q1d')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uhod2gi1ukjmyzzp5xw15zjz', 'function': {'arguments': '{\"a\":10,\"b\":50}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 431, 'total_tokens': 475}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea7980af-644c-4051-a2f6-9880401b756f-0', tool_calls=[{'name': 'add', 'args': {'a': 10, 'b': 50}, 'id': 'call_uhod2gi1ukjmyzzp5xw15zjz'}], usage_metadata={'input_tokens': 431, 'output_tokens': 44, 'total_tokens': 475})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

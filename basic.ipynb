{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Basic Usage (LLM + ChatModel only)\n",
    "Langchainçš„æ¡†æ¶ä¸‹é¢æœ‰ä¸»è¦åˆ†ç‚ºå…©ç¨®Model\n",
    "- LLM\n",
    "- Chat\n",
    "\n",
    "ç”±æ–¼Langchainä¸¦ä¸æä¾›ä»»ä½•Modelï¼Œæ‰€ä»¥LLMç›¸é—œçš„libraryéƒ½ä¸åœ¨langchain-coreè£¡é¢\n",
    "\n",
    "#### Langchainæœ€åŸºæœ¬çš„ç”¨æ³•\n",
    "`Prompt -> LLM -> Response`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything starts with LLM\n",
    "from langchain_core.messages import HumanMessage\n",
    "msg = HumanMessage(content='èŒ¶é¤å»³æ˜¯ä»€éº¼ï¼Ÿ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ä½¿ç”¨ChatModel (e.g. TogetherAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "model = ChatTogether(\n",
    "    together_api_key=os.environ['KEY_TOGETHERAI'],\n",
    "    model=\"Qwen/Qwen1.5-72B-Chat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke([msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### åˆ©ç”¨output_parserå°‡outputè®Šå¾—æ›´æ˜“è®€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='èŒ¶é¤å»³æ˜¯èµ·æºäºé¦™æ¸¯çš„ä¸€ç§é¤é¥®åœºæ‰€ï¼Œç»“åˆäº†ä¸­è¥¿é¤é¥®æ–‡åŒ–çš„ç‰¹è‰²ã€‚å®ƒæä¾›å¤šå…ƒåŒ–ã€ä»·å»‰ç‰©ç¾çš„é£Ÿç‰©é¸æ“‡ï¼Œé€šå¸¸æ—¢æœ‰ä¸­å¼ç‚¹å¿ƒã€é¢é£Ÿï¼Œä¹Ÿæœ‰è¥¿å¼çš„æ±‰å ¡ã€å’–å•¡ã€å¥¶èŒ¶ç­‰ã€‚èŒ¶é¤å»³çš„èœå•é€šå¸¸å¾ˆå¹¿æ³›ï¼Œé¡¾å®¢å¯ä»¥åœ¨ä¸€ä¸ªåœ°æ–¹äº«å—åˆ°å¤šç§ç±»å‹çš„é¤ç‚¹ï¼Œé€‚åˆå¿«èŠ‚å¥çš„ç”Ÿæ´»æ–¹å¼ã€‚èŒ¶é¤å…æ–‡åŒ–åœ¨é¦™æ¸¯æå…¶æµè¡Œï¼Œå¹¶é€æ¸åœ¨å…¶ä»–åœ°åŒºä¹Ÿå—åˆ°æ¬¢è¿ã€‚å®ƒä»¬é€šå¸¸æœ‰ç‹¬ç‰¹çš„è£…é¥°é£æ ¼å’Œå¿«æ·çš„æœåŠ¡æ–¹å¼ï¼Œæ˜¯ä½“éªŒé¦™æ¸¯å½“åœ°é£æƒ…çš„å¥½å»å¤„ã€‚' response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 23, 'total_tokens': 131}, 'model_name': 'Qwen/Qwen1.5-72B-Chat', 'system_fingerprint': None, 'finish_reason': 'eos', 'logprobs': None} id='run-f9eb908a-b528-4fd2-a74d-8c98bb558b75-0' usage_metadata={'input_tokens': 23, 'output_tokens': 108, 'total_tokens': 131}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "èŒ¶é¤å»³æ˜¯èµ·æºäºé¦™æ¸¯çš„ä¸€ç§é¤é¥®åœºæ‰€ï¼Œç»“åˆäº†ä¸­è¥¿é¤é¥®æ–‡åŒ–çš„ç‰¹è‰²ã€‚å®ƒæä¾›å¤šå…ƒåŒ–ã€ä»·å»‰ç‰©ç¾çš„é£Ÿç‰©é¸æ“‡ï¼Œé€šå¸¸æ—¢æœ‰ä¸­å¼ç‚¹å¿ƒã€é¢é£Ÿï¼Œä¹Ÿæœ‰è¥¿å¼çš„æ±‰å ¡ã€å’–å•¡ã€å¥¶èŒ¶ç­‰ã€‚èŒ¶é¤å»³çš„èœå•é€šå¸¸å¾ˆå¹¿æ³›ï¼Œé¡¾å®¢å¯ä»¥åœ¨ä¸€ä¸ªåœ°æ–¹äº«å—åˆ°å¤šç§ç±»å‹çš„é¤ç‚¹ï¼Œé€‚åˆå¿«èŠ‚å¥çš„ç”Ÿæ´»æ–¹å¼ã€‚èŒ¶é¤å…æ–‡åŒ–åœ¨é¦™æ¸¯æå…¶æµè¡Œï¼Œå¹¶é€æ¸åœ¨å…¶ä»–åœ°åŒºä¹Ÿå—åˆ°æ¬¢è¿ã€‚å®ƒä»¬é€šå¸¸æœ‰ç‹¬ç‰¹çš„è£…é¥°é£æ ¼å’Œå¿«æ·çš„æœåŠ¡æ–¹å¼ï¼Œæ˜¯ä½“éªŒé¦™æ¸¯å½“åœ°é£æƒ…çš„å¥½å»å¤„ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "p = StrOutputParser()\n",
    "# print(type(p))\n",
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### åŠ å…¥SystemMessage (Instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "system_message = \"\"\"\n",
    "å¿…é ˆä»¥ç¹é«”ä¸­æ–‡å›ç­”\n",
    "å›ç­”æ™‚åªä»¥','åˆ†éš”æ¯å€‹é …ç›®ï¼Œä¸¦ä»¥æœ€ç°¡çŸ­çš„æ–¹å¼å›ç­”ï¼Œä¾‹å¦‚ï¼š\n",
    "ä¸€,äºŒ,ä¸‰,...\n",
    "\"\"\"\n",
    "human_message = \"\"\"\n",
    "è«‹åˆ—èˆ‰èŒ¶é¤å»³ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”\n",
    "\"\"\"\n",
    "msg_list = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=human_message)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke(msg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è è˜¿æ²¹,å¥¶èŒ¶,è¥¿å¤šå£«,ç‚¸é›ç¿¼,è›‹æ’»,çŒªæ‰’åŒ…,ç‚’è›‹å¤š,é›²åé¢,ç‰›è‚‰ä¸¸,ç¾…å®‹æ¹¯\n"
     ]
    }
   ],
   "source": [
    "print(p.invoke(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structured Data Parser\n",
    "https://python.langchain.com/v0.2/docs/concepts/#output-parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['è è˜¿æ²¹', 'å¥¶èŒ¶', 'è¥¿å¤šå£«', 'ç‚¸é›ç¿¼', 'è›‹æ’»', 'çŒªæ‰’åŒ…', 'ç‚’è›‹å¤š', 'é›²åé¢', 'ç‰›è‚‰ä¸¸', 'ç¾…å®‹æ¹¯']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csvp = CommaSeparatedListOutputParser()\n",
    "parsed_res = csvp.invoke(res)\n",
    "print(type(parsed_res))\n",
    "print(parsed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ç”¨PromptTemplateæ›´æ–¹ä¾¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", \"è«‹åˆ—èˆ‰{place}ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”\"),\n",
    "])\n",
    "\n",
    "prompt_value = prompt_template.invoke(\n",
    "    {\n",
    "        'place': 'æ—¥æœ¬'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"\\nå¿…é ˆä»¥ç¹é«”ä¸­æ–‡å›ç­”\\nå›ç­”æ™‚åªä»¥','åˆ†éš”æ¯å€‹é …ç›®ï¼Œä¸¦ä»¥æœ€ç°¡çŸ­çš„æ–¹å¼å›ç­”ï¼Œä¾‹å¦‚ï¼š\\nä¸€,äºŒ,ä¸‰,...\\n\"), HumanMessage(content='è«‹åˆ—èˆ‰æ—¥æœ¬ä¸å¤šé10ç¨®æœ€ç†±é–€çš„é£Ÿç‰©ï¼Œä¸è‚¯å®šçš„ä¸è¦å›ç­”')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_csv = csvp.invoke(model.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å¯¿å¸', 'æ‹‰éºµ', 'å¤©å¦‡ç½—', 'çƒ§è‚‰', 'ç« é±¼çƒ§', 'äº²å­ä¸¼', 'ç‚¸é¸¡', 'åˆºèº«', 'å’Œç‰›', 'ä¾¿å½“']\n"
     ]
    }
   ],
   "source": [
    "print(japan_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ä»¥steamingçš„æ–¹å¼å›ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ä½ æ˜¯ä¸€å€‹æ—¥æœ¬è¼•å°èªªä½œå®¶ï¼Œå¯«ä½œé¢¨æ ¼è¦æ¨¡ä»¿å·åŸç¤«ï¼Œè«‹ä»¥ç”¨æˆ¶çš„åå­—å‘½åä¸»è§’ï¼Œä¸¦ä»¥æä¾›çš„é—œéµå­—å»å¯«ä¸€å€‹å¤§ç´„400å­—çš„çŸ­ç¯‡æ•…äº‹ã€‚æ•…äº‹å¿…é ˆä»¥ç¹é«”ä¸­æ–‡ç·¨å¯«ã€‚'), AIMessage(content='è«‹å•ä½ æ€æ¨£ç¨±å‘¼ï¼Ÿ'), HumanMessage(content='æˆ‘çš„åå­—å«å½Œè±†å­'), AIMessage(content='ä½ å¥½å½Œè±†å­ï¼Œè«‹å•ä½ æƒ³ä»¥ä»€éº¼ä½œé¡Œæå¯«é€™å€‹æ•…äº‹å‘¢ï¼Ÿ'), HumanMessage(content='æˆ‘æƒ³ä»¥é¬¼ï¼Œæ‰é¬¼ï¼Œè¦ªæƒ…ï¼Œæ‹¯æ•‘ä¸–ç•Œç‚ºé¡Œæå¯«é€™å€‹æ•…äº‹')]\n"
     ]
    }
   ],
   "source": [
    "author_system_message = \"\"\"ä½ æ˜¯ä¸€å€‹æ—¥æœ¬è¼•å°èªªä½œå®¶ï¼Œå¯«ä½œé¢¨æ ¼è¦æ¨¡ä»¿{author}ï¼Œè«‹ä»¥ç”¨æˆ¶çš„åå­—å‘½åä¸»è§’ï¼Œä¸¦ä»¥æä¾›çš„é—œéµå­—å»å¯«ä¸€å€‹å¤§ç´„400å­—çš„çŸ­ç¯‡æ•…äº‹ã€‚æ•…äº‹å¿…é ˆä»¥ç¹é«”ä¸­æ–‡ç·¨å¯«ã€‚\"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", author_system_message),\n",
    "    (\"ai\", \"è«‹å•ä½ æ€æ¨£ç¨±å‘¼ï¼Ÿ\"),\n",
    "    (\"human\", \"æˆ‘çš„åå­—å«{username}\"),\n",
    "    (\"ai\", \"ä½ å¥½{username}ï¼Œè«‹å•ä½ æƒ³ä»¥ä»€éº¼ä½œé¡Œæå¯«é€™å€‹æ•…äº‹å‘¢ï¼Ÿ\"),\n",
    "    (\"human\", \"æˆ‘æƒ³ä»¥{topics}ç‚ºé¡Œæå¯«é€™å€‹æ•…äº‹\"),\n",
    "])\n",
    "prompt_value = prompt_template2.invoke(\n",
    "    {\n",
    "        \"author\": \"å·åŸç¤«\",\n",
    "        \"username\": \"å½Œè±†å­\",\n",
    "        \"topics\": \"é¬¼ï¼Œæ‰é¬¼ï¼Œè¦ªæƒ…ï¼Œæ‹¯æ•‘ä¸–ç•Œ\"\n",
    "    }\n",
    ")\n",
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•…äº‹|å|ç¨±|ï¼š|ã€Š||å½Œ|è±†|å­|çš„||è©›|å’’|ä¹‹|å½±|ã€‹|\n",
      "\n",
      "|åœ¨|ä¸€å€‹|è¢«|é¬¼|æ€ª|è‚†|è™|çš„ä¸–ç•Œ|ä¸­|ï¼Œ|å|ç‚º||å½Œ|è±†|å­|çš„|å°‘å¥³|ï¼Œ|æ“æœ‰|è‘—|çœ‹|ç©¿|é‚ª|æƒ¡|éˆ|é­‚|çš„|é›™|çœ¼|ã€‚|å¥¹çš„|æ‘å­|è¢«|ä¸€å€‹|å|ç‚º|ã€Œ|è¡€|å’’|é¬¼|ç‹|ã€|çš„|å¼·|å¤§|éˆ|é«”|çµ±|æ²»|ï¼Œ|æ‘æ°‘ä»¬|ç”Ÿæ´»åœ¨|æ||æ‡¼|ä¹‹ä¸‹|ã€‚||å½Œ|è±†|å­|çš„|çˆ¶è¦ª|ï¼Œ|æ›¾|æ˜¯ä¸€ä½|å‹‡|çŒ›|çš„|æ‰|é¬¼|å¸«|ï¼Œ|ä½†åœ¨|èˆ‡|è¡€|å’’|é¬¼|ç‹|çš„|æˆ°|é¬¥|ä¸­|å¤±||è¹¤|ï¼Œ|ç•™|çµ¦|å¥¹|ä¸€æœ¬|å°|å°|è‘—|å¤è€|å’’|è¡“|çš„|æ›¸|ã€‚\n",
      "\n",
      "|æ™‚|å…‰|è|è‹’|ï¼Œ||å½Œ|è±†|å­|éˆ|é­‚|æ·±|è™•|çš„|å‹‡|æ°£|è¢«|è¦ª|æƒ…|çš„|ç‰½|æ›|é»|ç‡ƒ|ã€‚|å¥¹|æ±º|å¿ƒ|ç¹¼|æ‰¿|çˆ¶è¦ª|çš„|ä½¿å‘½|ï¼Œ|è¸ä¸Š|æ‹¯æ•‘|æ‘å­|çš„|æ—…ç¨‹|ã€‚|æ›¸|ä¸­çš„|å’’|è¡“|æˆç‚º|å¥¹|å”¯ä¸€çš„|æ­¦å™¨|ï¼Œ|æ¯|ä¸€å€‹|ç¬¦|å’’|éƒ½||è˜Š|å«|è‘—|æœªçŸ¥|çš„åŠ›é‡|ã€‚|å¥¹|å­¸|æœƒ|äº†|å¦‚ä½•||é§•||é¦­|éˆ|åŠ›|ï¼Œ|èˆ‡|é¬¼|æ€ª|å°|å³™|ï¼Œ|ä½†|æ¯æ¬¡|æˆ°|é¬¥|ï¼Œ|å¥¹|éƒ½ä¸|ç¦|æƒ³èµ·|èˆ‡|çˆ¶è¦ª|å…±|åº¦|çš„|æ™‚|å…‰|ã€‚\n",
      "\n",
      "|åœ¨|ä¸€æ¬¡æ¬¡|çš„|æŒ‘|æˆ°|ä¸­|ï¼Œ||å½Œ|è±†|å­|é€||æ¼¸|å¼·|å¤§|ï¼Œ|å¥¹|æ­|é–‹|äº†|è¡€|å’’|é¬¼|ç‹|çš„|çœŸ|é¢ç›®|ï¼š|ä¸€å€‹|è¢«|æ·±|å±¤||è©›|å’’|çš„|éˆ|é­‚|ï¼Œ|æ¸´æœ›|æ•‘||è´–|ã€‚|ç‚ºäº†|æ‹¯æ•‘|é€™å€‹|æ‰­æ›²|çš„ä¸–ç•Œ|ï¼Œ||å½Œ|è±†|å­|é¸æ“‡|äº†|å¯¬|æ•|è€Œé|æ¶ˆ|æ»…|ï¼Œ|å¥¹|ä»¥|è¦ª|æƒ…|çš„|æº«|æš–|å’Œ|å‹‡|æ°£|çš„|å…‰èŠ’|ï¼Œ|è©¦|åœ–|è§£|é–‹|è¡€|å’’|é¬¼|ç‹|èº«|ä¸Šçš„|æ·|é–|ã€‚\n",
      "\n",
      "|å…©å€‹|éˆ|é­‚|åœ¨|é»‘æš—|ä¸­|ç¢°æ’|ï¼Œ|æ‹¯æ•‘|èˆ‡|è¢«|æ‹¯æ•‘|ï¼Œ|è¦ª|æƒ…|èˆ‡|å‹‡|æ°£|çš„|äº¤||ç¹”|ï¼Œ|å½¢æˆ|äº†ä¸€|è‚¡|ç„¡æ³•|å¿½|è¦–|çš„åŠ›é‡|ã€‚|æœ€å¾Œ|ï¼Œ|ç•¶||å½Œ|è±†|å­|çš„|å’’|è¡“|èˆ‡|å¥¹|å…§|å¿ƒ|çš„|æ„›|ç›¸|èåˆ|ï¼Œ|è¡€|å’’|é¬¼|ç‹|çš„||è©›|å’’|çµ‚æ–¼|è§£|é–‹|ï¼Œ|ä¸–ç•Œ|é‡|æ­¸|å’Œå¹³|ã€‚|è€Œ|å¥¹|ï¼Œ|ä¹Ÿ|æ‰¾åˆ°äº†|å¤±||è¹¤|çˆ¶è¦ª|çš„|ç—•|è·¡|ï¼Œ|ä¸€å€‹|æ–°çš„|å†’|éšª|æ­£|ç­‰å¾…|è‘—|å¥¹|ã€‚\n",
      "\n",
      "|é€™|å°±æ˜¯|ã€Š||å½Œ|è±†|å­|çš„||è©›|å’’|ä¹‹|å½±|ã€‹ï¼Œ|ä¸€å€‹|é—œæ–¼|æˆé•·|ã€|å‹‡|æ°£|èˆ‡|è¦ª|æƒ…|çš„æ•…äº‹|ï¼Œ|ä¸€å€‹|å°‘å¥³|å¦‚ä½•|ä»¥|æ„›|èˆ‡|ç†è§£|æ‹¯æ•‘|ä¸–ç•Œ|ï¼Œ|ä¸¦|è¸ä¸Š|å°‹|æ‰¾|çˆ¶è¦ª|çš„|å¾|é€”|ã€‚||"
     ]
    }
   ],
   "source": [
    "for res in model.stream(prompt_value):\n",
    "    print(res.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL: LangChain Expression Language\n",
    "æ€æ¨£ç”¨LCELç°¡åŒ–æ—¥æœ¬è¼•å°èªªå®¶çš„Chainå‘¢ï¼Ÿ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnovel = prompt_template2 | model | p\n",
    "res = jnovel.invoke(\n",
    "    {\n",
    "        \"author\": \"æ”¯å€‰å‡ç ‚\",\n",
    "        \"username\": \"äº¨åˆ©\",\n",
    "        \"topics\": \"ç‹¼ï¼Œé¦™è¾›æ–™ï¼ŒåŒ—æ–¹ï¼Œæ—…è¡Œå•†äºº\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.parse(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnovel2 = prompt_template2 | model | p\n",
    "for res in jnovel2.stream(\n",
    "    {\n",
    "        \"author\": \"æ”¯å€‰å‡ç ‚\",\n",
    "        \"username\": \"äº¨åˆ©\",\n",
    "        \"topics\": \"ç‹¼ï¼Œé¦™è¾›æ–™ï¼ŒåŒ—æ–¹ï¼Œæ—…è¡Œå•†äºº\"\n",
    "    }):\n",
    "    print(res, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### å•é¡Œï¼šPrintçš„ç‚ºä½•ä¸å†æ˜¯res.content?\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/how_to/streaming/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å‰å¤§çš„LangChain: Runnable\n",
    "https://python.langchain.com/v0.2/docs/concepts/#runnable-interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Track: Tools Calling ğŸ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistralai/Mixtral-8x22B-Instruct-v0.1\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "better_model = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"KEY_TOGETHERAI\"],\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",)\n",
    "\n",
    "model_with_tools = better_model.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google gemini-pro\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"service_account.json\"\n",
    "\n",
    "better_model = ChatVertexAI(\n",
    "    model=\"gemini-pro\",\n",
    "    project='vtxclass',\n",
    "    location=\"asia-southeast1\"\n",
    ")\n",
    "model_with_tools = better_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_5zmcexsfp4qol6jx7btscy96'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_jm696xbz41a56mxr8ugrx56m'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is 3 * 12? And what is 11 + 49?\"\n",
    "\n",
    "model_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? And what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6potaftdvkopvoffgh72nn3v', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_bxw5gzlgpgt01def5mzz1q1d', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 303, 'total_tokens': 387}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e3d46cdf-ce0f-460d-ac5c-28f695ab7a07-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_6potaftdvkopvoffgh72nn3v'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_bxw5gzlgpgt01def5mzz1q1d'}], usage_metadata={'input_tokens': 303, 'output_tokens': 84, 'total_tokens': 387}),\n",
       " ToolMessage(content='36', tool_call_id='call_6potaftdvkopvoffgh72nn3v'),\n",
       " ToolMessage(content='60', tool_call_id='call_bxw5gzlgpgt01def5mzz1q1d')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uhod2gi1ukjmyzzp5xw15zjz', 'function': {'arguments': '{\"a\":10,\"b\":50}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 431, 'total_tokens': 475}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea7980af-644c-4051-a2f6-9880401b756f-0', tool_calls=[{'name': 'add', 'args': {'a': 10, 'b': 50}, 'id': 'call_uhod2gi1ukjmyzzp5xw15zjz'}], usage_metadata={'input_tokens': 431, 'output_tokens': 44, 'total_tokens': 475})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
